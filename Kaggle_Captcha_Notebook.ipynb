{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":77379,"databundleVersionId":8432179,"sourceType":"competition"},{"sourceId":11935616,"sourceType":"datasetVersion","datasetId":7503935}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Kaggle CAPTCHA Solver\n\nThis notebook was created to participate in the Kaggle CAPTCHA competition. It covers data loading, preprocessing, augmentation, model building, training, and submission generation.","metadata":{}},{"cell_type":"markdown","source":"## 1. Импорт библиотек¶\n\nПодключаем все необходимые библиотеки.","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras import layers, models, Input\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\nfrom tensorflow.keras.applications import MobileNetV2\nimport numpy as np\nimport pandas as pd\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T21:52:27.012256Z","iopub.execute_input":"2025-05-24T21:52:27.012732Z","iopub.status.idle":"2025-05-24T21:52:27.038652Z","shell.execute_reply.started":"2025-05-24T21:52:27.012705Z","shell.execute_reply":"2025-05-24T21:52:27.037602Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/d/vasiliifede/mipt-dl-captcha/sample_submission.csv\n/kaggle/input/d/vasiliifede/mipt-dl-captcha/images.npy\n/kaggle/input/d/vasiliifede/mipt-dl-captcha/labels.npy\n/kaggle/input/d/vasiliifede/mipt-dl-captcha/images_sub.npy\n","output_type":"stream"}],"execution_count":29},{"cell_type":"markdown","source":"## 2. Загрузка данных\nЗагружаем обучающие и тестовые наборы.","metadata":{}},{"cell_type":"code","source":"# Загрузка датасетов\nimages = np.load('/kaggle/input/d/vasiliifede/mipt-dl-captcha/images.npy')\nimages_sub  = np.load('/kaggle/input/d/vasiliifede/mipt-dl-captcha/images_sub.npy')\nlabels = np.load('/kaggle/input/d/vasiliifede/mipt-dl-captcha/labels.npy')\nsample_sub = pd.read_csv('/kaggle/input/d/vasiliifede/mipt-dl-captcha/sample_submission.csv')\n\nprint(\"images:\", images.shape)\nprint(\"images_sub: \", images_sub.shape)\nprint('labels: ', labels.shape)\nprint(\"sample submission:\", sample_sub.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T16:24:22.112544Z","iopub.execute_input":"2025-05-24T16:24:22.113005Z","iopub.status.idle":"2025-05-24T16:24:26.100544Z","shell.execute_reply.started":"2025-05-24T16:24:22.112979Z","shell.execute_reply":"2025-05-24T16:24:26.099697Z"}},"outputs":[{"name":"stdout","text":"images: (20000, 48, 48, 3)\nimages_sub:  (50000, 48, 48, 3)\nlabels:  (20000,)\nsample submission: (50000, 2)\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"## 3. Разбиение и нормализация\nДелим данные на тренировочную и валидационную выборки и нормализуем.","metadata":{}},{"cell_type":"code","source":"X = images.astype('float32') / 255.0\n\nX_train, X_val, y_train, y_val = train_test_split(\n    X, labels,\n    test_size=0.15,    # 15% под валидацию\n    random_state=42,   # для фиксированного разбиения\n    shuffle=True,\n    stratify=labels    # сбалансирует классы\n)\nprint(\"Train:\", X_train.shape, y_train.shape)\nprint(\"Val:  \", X_val.shape,   y_val.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T16:35:04.149029Z","iopub.execute_input":"2025-05-24T16:35:04.149803Z","iopub.status.idle":"2025-05-24T16:35:04.765349Z","shell.execute_reply.started":"2025-05-24T16:35:04.149743Z","shell.execute_reply":"2025-05-24T16:35:04.764268Z"}},"outputs":[{"name":"stdout","text":"Train: (17000, 48, 48, 3) (17000,)\nVal:   (3000, 48, 48, 3) (3000,)\n","output_type":"stream"}],"execution_count":4},{"cell_type":"markdown","source":"## 4. Создание генераторов\nАугментация данных для тренировки и простая нормализация для валидации.","metadata":{}},{"cell_type":"code","source":"\n# нормализация и аугментация для train\ntrain_datagen = ImageDataGenerator(\n    rescale=1./255,\n    rotation_range=45,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    brightness_range=(0.7,1.3),\n    channel_shift_range=0.5,    # изменяем еще цвета\n    horizontal_flip=True,\n    validation_split=0.15\n)\n\n# для валидации — только rescale\nval_datagen = ImageDataGenerator(\n    rescale=1./255,\n    validation_split=0.15\n)\n\ntrain_gen = train_datagen.flow(\n    images, labels,\n    subset='training',\n    batch_size=64,\n    shuffle=True\n)\nval_gen = val_datagen.flow(\n    images, labels,\n    subset='validation',\n    batch_size=64,\n    shuffle=False\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T16:37:31.400691Z","iopub.execute_input":"2025-05-24T16:37:31.401028Z","iopub.status.idle":"2025-05-24T16:37:31.604695Z","shell.execute_reply.started":"2025-05-24T16:37:31.401006Z","shell.execute_reply":"2025-05-24T16:37:31.603731Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"## 5. Определение модели\nИспользуем MobileNetV2 в качестве базовой модели с дополнительными головными слоями.","metadata":{}},{"cell_type":"code","source":"#  модель без головы\nbase_model = MobileNetV2(\n    include_top=False,\n    weights = 'imagenet',\n    input_shape = (48, 48, 3)\n)\n\n# заморозим все слои на этапе обучения головы\nbase_model.trainabale = False\n\n# добавляем головные слои\nx = base_model.output\nx = layers.GlobalAveragePooling2D()(x)\nx = layers.Dense(256, activation='relu')(x)\nx = layers.BatchNormalization()(x)\nx = layers.Dropout(0.5)(x)\noutputs = layers.Dense(26, activation='softmax')(x)\n\n# склеиваем части модели\nmodel = models.Model(inputs=base_model.input, outputs=outputs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T19:35:37.978114Z","iopub.execute_input":"2025-05-24T19:35:37.978430Z","iopub.status.idle":"2025-05-24T19:35:38.805618Z","shell.execute_reply.started":"2025-05-24T19:35:37.978406Z","shell.execute_reply":"2025-05-24T19:35:38.804852Z"}},"outputs":[{"name":"stderr","text":"/tmp/ipykernel_35/1079731079.py:2: UserWarning: `input_shape` is undefined or non-square, or `rows` is not in [96, 128, 160, 192, 224]. Weights for input shape (224, 224) will be loaded as the default.\n  base_model = MobileNetV2(\n","output_type":"stream"}],"execution_count":25},{"cell_type":"code","source":"# Компиляция модели\nmodel.compile(\n    optimizer=Adam(learning_rate=1e-3),\n    loss='sparse_categorical_crossentropy',\n    metrics=['accuracy']\n)\n\ncallbacks = [\n    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1),\n    EarlyStopping(monitor='val_loss', patience=7, restore_best_weights=True, verbose=1),\n    ModelCheckpoint('best_model.h5', save_best_only=True, monitor='val_accuracy', verbose=1)\n]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T19:35:42.908007Z","iopub.execute_input":"2025-05-24T19:35:42.908317Z","iopub.status.idle":"2025-05-24T19:35:42.919853Z","shell.execute_reply.started":"2025-05-24T19:35:42.908296Z","shell.execute_reply":"2025-05-24T19:35:42.918958Z"}},"outputs":[],"execution_count":26},{"cell_type":"markdown","source":"## 6. Обучение модели\nУстанавливаем обратные вызовы и обучаем модель","metadata":{}},{"cell_type":"code","source":"# Обучение\nhistory = model.fit(\n    train_gen,\n    validation_data=val_gen,\n    epochs=100,\n    callbacks=callbacks\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T19:36:01.075499Z","iopub.execute_input":"2025-05-24T19:36:01.075846Z","iopub.status.idle":"2025-05-24T21:40:22.413381Z","shell.execute_reply.started":"2025-05-24T19:36:01.075821Z","shell.execute_reply":"2025-05-24T21:40:22.410642Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Epoch 1/100\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385ms/step - accuracy: 0.0681 - loss: 3.9497\nEpoch 1: val_accuracy improved from -inf to 0.06633, saving model to best_model.h5\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 409ms/step - accuracy: 0.0682 - loss: 3.9483 - val_accuracy: 0.0663 - val_loss: 8.1903 - learning_rate: 0.0010\nEpoch 2/100\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387ms/step - accuracy: 0.1683 - loss: 2.9512\nEpoch 2: val_accuracy improved from 0.06633 to 0.10500, saving model to best_model.h5\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 401ms/step - accuracy: 0.1684 - loss: 2.9506 - val_accuracy: 0.1050 - val_loss: 6.5922 - learning_rate: 0.0010\nEpoch 3/100\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385ms/step - accuracy: 0.2994 - loss: 2.4002\nEpoch 3: val_accuracy did not improve from 0.10500\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 398ms/step - accuracy: 0.2993 - loss: 2.4004 - val_accuracy: 0.0933 - val_loss: 7.6516 - learning_rate: 0.0010\nEpoch 4/100\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383ms/step - accuracy: 0.2956 - loss: 2.4156\nEpoch 4: val_accuracy did not improve from 0.10500\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 394ms/step - accuracy: 0.2957 - loss: 2.4152 - val_accuracy: 0.0687 - val_loss: 8.8304 - learning_rate: 0.0010\nEpoch 5/100\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384ms/step - accuracy: 0.4064 - loss: 1.9458\nEpoch 5: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n\nEpoch 5: val_accuracy improved from 0.10500 to 0.16100, saving model to best_model.h5\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 397ms/step - accuracy: 0.4064 - loss: 1.9457 - val_accuracy: 0.1610 - val_loss: 7.2431 - learning_rate: 0.0010\nEpoch 6/100\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383ms/step - accuracy: 0.4746 - loss: 1.6859\nEpoch 6: val_accuracy improved from 0.16100 to 0.32567, saving model to best_model.h5\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 396ms/step - accuracy: 0.4747 - loss: 1.6856 - val_accuracy: 0.3257 - val_loss: 3.8033 - learning_rate: 5.0000e-04\nEpoch 7/100\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382ms/step - accuracy: 0.5503 - loss: 1.4486\nEpoch 7: val_accuracy improved from 0.32567 to 0.48200, saving model to best_model.h5\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 396ms/step - accuracy: 0.5504 - loss: 1.4484 - val_accuracy: 0.4820 - val_loss: 2.1978 - learning_rate: 5.0000e-04\nEpoch 8/100\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380ms/step - accuracy: 0.5937 - loss: 1.2840\nEpoch 8: val_accuracy improved from 0.48200 to 0.56067, saving model to best_model.h5\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 395ms/step - accuracy: 0.5937 - loss: 1.2840 - val_accuracy: 0.5607 - val_loss: 1.9203 - learning_rate: 5.0000e-04\nEpoch 9/100\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379ms/step - accuracy: 0.6349 - loss: 1.1582\nEpoch 9: val_accuracy improved from 0.56067 to 0.62367, saving model to best_model.h5\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 393ms/step - accuracy: 0.6349 - loss: 1.1582 - val_accuracy: 0.6237 - val_loss: 1.5675 - learning_rate: 5.0000e-04\nEpoch 10/100\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381ms/step - accuracy: 0.6621 - loss: 1.0765\nEpoch 10: val_accuracy improved from 0.62367 to 0.64767, saving model to best_model.h5\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 395ms/step - accuracy: 0.6621 - loss: 1.0765 - val_accuracy: 0.6477 - val_loss: 1.3281 - learning_rate: 5.0000e-04\nEpoch 11/100\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383ms/step - accuracy: 0.6782 - loss: 1.0269\nEpoch 11: val_accuracy improved from 0.64767 to 0.65767, saving model to best_model.h5\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 398ms/step - accuracy: 0.6782 - loss: 1.0269 - val_accuracy: 0.6577 - val_loss: 1.2178 - learning_rate: 5.0000e-04\nEpoch 12/100\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386ms/step - accuracy: 0.7001 - loss: 0.9591\nEpoch 12: val_accuracy improved from 0.65767 to 0.73500, saving model to best_model.h5\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 400ms/step - accuracy: 0.7002 - loss: 0.9590 - val_accuracy: 0.7350 - val_loss: 0.8966 - learning_rate: 5.0000e-04\nEpoch 13/100\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379ms/step - accuracy: 0.7122 - loss: 0.9242\nEpoch 13: val_accuracy did not improve from 0.73500\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 392ms/step - accuracy: 0.7122 - loss: 0.9241 - val_accuracy: 0.7140 - val_loss: 1.0071 - learning_rate: 5.0000e-04\nEpoch 14/100\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381ms/step - accuracy: 0.7263 - loss: 0.8763\nEpoch 14: val_accuracy improved from 0.73500 to 0.73633, saving model to best_model.h5\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 403ms/step - accuracy: 0.7263 - loss: 0.8762 - val_accuracy: 0.7363 - val_loss: 1.0082 - learning_rate: 5.0000e-04\nEpoch 15/100\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383ms/step - accuracy: 0.7347 - loss: 0.8378\nEpoch 15: val_accuracy improved from 0.73633 to 0.76533, saving model to best_model.h5\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 397ms/step - accuracy: 0.7347 - loss: 0.8377 - val_accuracy: 0.7653 - val_loss: 0.8213 - learning_rate: 5.0000e-04\nEpoch 16/100\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382ms/step - accuracy: 0.7512 - loss: 0.7898\nEpoch 16: val_accuracy improved from 0.76533 to 0.77100, saving model to best_model.h5\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 396ms/step - accuracy: 0.7512 - loss: 0.7899 - val_accuracy: 0.7710 - val_loss: 0.8535 - learning_rate: 5.0000e-04\nEpoch 17/100\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381ms/step - accuracy: 0.7699 - loss: 0.7408\nEpoch 17: val_accuracy did not improve from 0.77100\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 393ms/step - accuracy: 0.7699 - loss: 0.7408 - val_accuracy: 0.7517 - val_loss: 0.8845 - learning_rate: 5.0000e-04\nEpoch 18/100\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383ms/step - accuracy: 0.7786 - loss: 0.7103\nEpoch 18: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n\nEpoch 18: val_accuracy improved from 0.77100 to 0.77733, saving model to best_model.h5\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 397ms/step - accuracy: 0.7786 - loss: 0.7103 - val_accuracy: 0.7773 - val_loss: 0.8731 - learning_rate: 5.0000e-04\nEpoch 19/100\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379ms/step - accuracy: 0.7993 - loss: 0.6472\nEpoch 19: val_accuracy improved from 0.77733 to 0.83667, saving model to best_model.h5\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 393ms/step - accuracy: 0.7993 - loss: 0.6471 - val_accuracy: 0.8367 - val_loss: 0.5544 - learning_rate: 2.5000e-04\nEpoch 20/100\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378ms/step - accuracy: 0.8121 - loss: 0.5992\nEpoch 20: val_accuracy improved from 0.83667 to 0.84500, saving model to best_model.h5\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 392ms/step - accuracy: 0.8121 - loss: 0.5992 - val_accuracy: 0.8450 - val_loss: 0.5307 - learning_rate: 2.5000e-04\nEpoch 21/100\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385ms/step - accuracy: 0.8206 - loss: 0.5662\nEpoch 21: val_accuracy did not improve from 0.84500\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 397ms/step - accuracy: 0.8206 - loss: 0.5663 - val_accuracy: 0.8113 - val_loss: 0.6940 - learning_rate: 2.5000e-04\nEpoch 22/100\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385ms/step - accuracy: 0.8197 - loss: 0.5615\nEpoch 22: val_accuracy improved from 0.84500 to 0.85500, saving model to best_model.h5\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 399ms/step - accuracy: 0.8197 - loss: 0.5615 - val_accuracy: 0.8550 - val_loss: 0.4773 - learning_rate: 2.5000e-04\nEpoch 23/100\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387ms/step - accuracy: 0.8226 - loss: 0.5546\nEpoch 23: val_accuracy did not improve from 0.85500\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 399ms/step - accuracy: 0.8227 - loss: 0.5545 - val_accuracy: 0.8533 - val_loss: 0.4606 - learning_rate: 2.5000e-04\nEpoch 24/100\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385ms/step - accuracy: 0.8240 - loss: 0.5437\nEpoch 24: val_accuracy improved from 0.85500 to 0.85533, saving model to best_model.h5\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 399ms/step - accuracy: 0.8240 - loss: 0.5437 - val_accuracy: 0.8553 - val_loss: 0.4472 - learning_rate: 2.5000e-04\nEpoch 25/100\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382ms/step - accuracy: 0.8329 - loss: 0.5183\nEpoch 25: val_accuracy improved from 0.85533 to 0.86933, saving model to best_model.h5\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 396ms/step - accuracy: 0.8329 - loss: 0.5183 - val_accuracy: 0.8693 - val_loss: 0.4335 - learning_rate: 2.5000e-04\nEpoch 26/100\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387ms/step - accuracy: 0.8338 - loss: 0.5270\nEpoch 26: val_accuracy did not improve from 0.86933\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 399ms/step - accuracy: 0.8338 - loss: 0.5270 - val_accuracy: 0.8663 - val_loss: 0.4337 - learning_rate: 2.5000e-04\nEpoch 27/100\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385ms/step - accuracy: 0.8368 - loss: 0.5018\nEpoch 27: val_accuracy did not improve from 0.86933\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 399ms/step - accuracy: 0.8368 - loss: 0.5017 - val_accuracy: 0.8647 - val_loss: 0.4402 - learning_rate: 2.5000e-04\nEpoch 28/100\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384ms/step - accuracy: 0.8452 - loss: 0.4887\nEpoch 28: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n\nEpoch 28: val_accuracy did not improve from 0.86933\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 396ms/step - accuracy: 0.8452 - loss: 0.4887 - val_accuracy: 0.8607 - val_loss: 0.4700 - learning_rate: 2.5000e-04\nEpoch 29/100\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382ms/step - accuracy: 0.8581 - loss: 0.4510\nEpoch 29: val_accuracy improved from 0.86933 to 0.88567, saving model to best_model.h5\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 396ms/step - accuracy: 0.8581 - loss: 0.4510 - val_accuracy: 0.8857 - val_loss: 0.3704 - learning_rate: 1.2500e-04\nEpoch 30/100\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386ms/step - accuracy: 0.8653 - loss: 0.4390\nEpoch 30: val_accuracy improved from 0.88567 to 0.89800, saving model to best_model.h5\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 400ms/step - accuracy: 0.8653 - loss: 0.4390 - val_accuracy: 0.8980 - val_loss: 0.3350 - learning_rate: 1.2500e-04\nEpoch 31/100\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381ms/step - accuracy: 0.8641 - loss: 0.4224\nEpoch 31: val_accuracy did not improve from 0.89800\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 394ms/step - accuracy: 0.8641 - loss: 0.4224 - val_accuracy: 0.8823 - val_loss: 0.3558 - learning_rate: 1.2500e-04\nEpoch 32/100\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 390ms/step - accuracy: 0.8661 - loss: 0.4144\nEpoch 32: val_accuracy did not improve from 0.89800\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 402ms/step - accuracy: 0.8661 - loss: 0.4144 - val_accuracy: 0.8877 - val_loss: 0.3523 - learning_rate: 1.2500e-04\nEpoch 33/100\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 393ms/step - accuracy: 0.8769 - loss: 0.3778\nEpoch 33: val_accuracy did not improve from 0.89800\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m108s\u001b[0m 406ms/step - accuracy: 0.8769 - loss: 0.3778 - val_accuracy: 0.8957 - val_loss: 0.3220 - learning_rate: 1.2500e-04\nEpoch 34/100\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388ms/step - accuracy: 0.8727 - loss: 0.3940\nEpoch 34: val_accuracy improved from 0.89800 to 0.90000, saving model to best_model.h5\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 403ms/step - accuracy: 0.8727 - loss: 0.3940 - val_accuracy: 0.9000 - val_loss: 0.2964 - learning_rate: 1.2500e-04\nEpoch 35/100\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386ms/step - accuracy: 0.8738 - loss: 0.3918\nEpoch 35: val_accuracy improved from 0.90000 to 0.90700, saving model to best_model.h5\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 400ms/step - accuracy: 0.8738 - loss: 0.3918 - val_accuracy: 0.9070 - val_loss: 0.2863 - learning_rate: 1.2500e-04\nEpoch 36/100\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 392ms/step - accuracy: 0.8751 - loss: 0.3853\nEpoch 36: val_accuracy did not improve from 0.90700\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 404ms/step - accuracy: 0.8751 - loss: 0.3853 - val_accuracy: 0.9007 - val_loss: 0.2979 - learning_rate: 1.2500e-04\nEpoch 37/100\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386ms/step - accuracy: 0.8792 - loss: 0.3751\nEpoch 37: val_accuracy improved from 0.90700 to 0.90733, saving model to best_model.h5\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 400ms/step - accuracy: 0.8792 - loss: 0.3751 - val_accuracy: 0.9073 - val_loss: 0.2874 - learning_rate: 1.2500e-04\nEpoch 38/100\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387ms/step - accuracy: 0.8815 - loss: 0.3777\nEpoch 38: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n\nEpoch 38: val_accuracy did not improve from 0.90733\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 399ms/step - accuracy: 0.8815 - loss: 0.3777 - val_accuracy: 0.9000 - val_loss: 0.3088 - learning_rate: 1.2500e-04\nEpoch 39/100\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 388ms/step - accuracy: 0.8824 - loss: 0.3685\nEpoch 39: val_accuracy did not improve from 0.90733\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 400ms/step - accuracy: 0.8824 - loss: 0.3685 - val_accuracy: 0.9073 - val_loss: 0.2834 - learning_rate: 6.2500e-05\nEpoch 40/100\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382ms/step - accuracy: 0.8942 - loss: 0.3306\nEpoch 40: val_accuracy improved from 0.90733 to 0.91000, saving model to best_model.h5\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 396ms/step - accuracy: 0.8942 - loss: 0.3306 - val_accuracy: 0.9100 - val_loss: 0.2758 - learning_rate: 6.2500e-05\nEpoch 41/100\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 384ms/step - accuracy: 0.8918 - loss: 0.3372\nEpoch 41: val_accuracy improved from 0.91000 to 0.91200, saving model to best_model.h5\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 397ms/step - accuracy: 0.8917 - loss: 0.3373 - val_accuracy: 0.9120 - val_loss: 0.2748 - learning_rate: 6.2500e-05\nEpoch 42/100\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381ms/step - accuracy: 0.8832 - loss: 0.3574\nEpoch 42: val_accuracy did not improve from 0.91200\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m107s\u001b[0m 401ms/step - accuracy: 0.8832 - loss: 0.3573 - val_accuracy: 0.9113 - val_loss: 0.2671 - learning_rate: 6.2500e-05\nEpoch 43/100\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383ms/step - accuracy: 0.8914 - loss: 0.3374\nEpoch 43: val_accuracy improved from 0.91200 to 0.91400, saving model to best_model.h5\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 399ms/step - accuracy: 0.8914 - loss: 0.3374 - val_accuracy: 0.9140 - val_loss: 0.2680 - learning_rate: 6.2500e-05\nEpoch 44/100\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382ms/step - accuracy: 0.8922 - loss: 0.3397\nEpoch 44: val_accuracy did not improve from 0.91400\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 394ms/step - accuracy: 0.8922 - loss: 0.3397 - val_accuracy: 0.9123 - val_loss: 0.2604 - learning_rate: 6.2500e-05\nEpoch 45/100\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381ms/step - accuracy: 0.8943 - loss: 0.3252\nEpoch 45: val_accuracy did not improve from 0.91400\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 393ms/step - accuracy: 0.8943 - loss: 0.3252 - val_accuracy: 0.9130 - val_loss: 0.2685 - learning_rate: 6.2500e-05\nEpoch 46/100\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382ms/step - accuracy: 0.8876 - loss: 0.3394\nEpoch 46: val_accuracy improved from 0.91400 to 0.91500, saving model to best_model.h5\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 396ms/step - accuracy: 0.8876 - loss: 0.3394 - val_accuracy: 0.9150 - val_loss: 0.2633 - learning_rate: 6.2500e-05\nEpoch 47/100\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382ms/step - accuracy: 0.8996 - loss: 0.3167\nEpoch 47: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n\nEpoch 47: val_accuracy did not improve from 0.91500\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 398ms/step - accuracy: 0.8995 - loss: 0.3167 - val_accuracy: 0.9017 - val_loss: 0.2830 - learning_rate: 6.2500e-05\nEpoch 48/100\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381ms/step - accuracy: 0.8934 - loss: 0.3244\nEpoch 48: val_accuracy did not improve from 0.91500\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 395ms/step - accuracy: 0.8934 - loss: 0.3244 - val_accuracy: 0.9083 - val_loss: 0.2746 - learning_rate: 3.1250e-05\nEpoch 49/100\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383ms/step - accuracy: 0.8910 - loss: 0.3324\nEpoch 49: val_accuracy did not improve from 0.91500\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 394ms/step - accuracy: 0.8910 - loss: 0.3323 - val_accuracy: 0.9110 - val_loss: 0.2606 - learning_rate: 3.1250e-05\nEpoch 50/100\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 385ms/step - accuracy: 0.9038 - loss: 0.3005\nEpoch 50: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n\nEpoch 50: val_accuracy did not improve from 0.91500\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 397ms/step - accuracy: 0.9038 - loss: 0.3006 - val_accuracy: 0.9100 - val_loss: 0.2612 - learning_rate: 3.1250e-05\nEpoch 51/100\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380ms/step - accuracy: 0.9025 - loss: 0.3009\nEpoch 51: val_accuracy did not improve from 0.91500\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 392ms/step - accuracy: 0.9025 - loss: 0.3009 - val_accuracy: 0.9147 - val_loss: 0.2562 - learning_rate: 1.5625e-05\nEpoch 52/100\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380ms/step - accuracy: 0.9049 - loss: 0.2965\nEpoch 52: val_accuracy did not improve from 0.91500\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 393ms/step - accuracy: 0.9049 - loss: 0.2965 - val_accuracy: 0.9133 - val_loss: 0.2539 - learning_rate: 1.5625e-05\nEpoch 53/100\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380ms/step - accuracy: 0.9038 - loss: 0.3029\nEpoch 53: val_accuracy improved from 0.91500 to 0.91600, saving model to best_model.h5\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 394ms/step - accuracy: 0.9038 - loss: 0.3029 - val_accuracy: 0.9160 - val_loss: 0.2512 - learning_rate: 1.5625e-05\nEpoch 54/100\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 386ms/step - accuracy: 0.8987 - loss: 0.3142\nEpoch 54: val_accuracy improved from 0.91600 to 0.91633, saving model to best_model.h5\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 400ms/step - accuracy: 0.8987 - loss: 0.3141 - val_accuracy: 0.9163 - val_loss: 0.2522 - learning_rate: 1.5625e-05\nEpoch 55/100\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381ms/step - accuracy: 0.9079 - loss: 0.2857\nEpoch 55: val_accuracy improved from 0.91633 to 0.91733, saving model to best_model.h5\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 395ms/step - accuracy: 0.9079 - loss: 0.2857 - val_accuracy: 0.9173 - val_loss: 0.2532 - learning_rate: 1.5625e-05\nEpoch 56/100\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379ms/step - accuracy: 0.9021 - loss: 0.3005\nEpoch 56: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n\nEpoch 56: val_accuracy did not improve from 0.91733\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 391ms/step - accuracy: 0.9021 - loss: 0.3005 - val_accuracy: 0.9167 - val_loss: 0.2519 - learning_rate: 1.5625e-05\nEpoch 57/100\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381ms/step - accuracy: 0.9042 - loss: 0.2907\nEpoch 57: val_accuracy improved from 0.91733 to 0.92033, saving model to best_model.h5\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 395ms/step - accuracy: 0.9042 - loss: 0.2907 - val_accuracy: 0.9203 - val_loss: 0.2480 - learning_rate: 7.8125e-06\nEpoch 58/100\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380ms/step - accuracy: 0.9029 - loss: 0.2951\nEpoch 58: val_accuracy did not improve from 0.92033\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 392ms/step - accuracy: 0.9029 - loss: 0.2951 - val_accuracy: 0.9197 - val_loss: 0.2462 - learning_rate: 7.8125e-06\nEpoch 59/100\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379ms/step - accuracy: 0.9032 - loss: 0.2868\nEpoch 59: val_accuracy did not improve from 0.92033\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 393ms/step - accuracy: 0.9032 - loss: 0.2869 - val_accuracy: 0.9190 - val_loss: 0.2483 - learning_rate: 7.8125e-06\nEpoch 60/100\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380ms/step - accuracy: 0.9026 - loss: 0.2939\nEpoch 60: val_accuracy improved from 0.92033 to 0.92167, saving model to best_model.h5\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 393ms/step - accuracy: 0.9026 - loss: 0.2939 - val_accuracy: 0.9217 - val_loss: 0.2477 - learning_rate: 7.8125e-06\nEpoch 61/100\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 378ms/step - accuracy: 0.9099 - loss: 0.2783\nEpoch 61: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n\nEpoch 61: val_accuracy did not improve from 0.92167\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 390ms/step - accuracy: 0.9099 - loss: 0.2784 - val_accuracy: 0.9210 - val_loss: 0.2470 - learning_rate: 7.8125e-06\nEpoch 62/100\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379ms/step - accuracy: 0.9101 - loss: 0.2786\nEpoch 62: val_accuracy did not improve from 0.92167\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 391ms/step - accuracy: 0.9101 - loss: 0.2786 - val_accuracy: 0.9213 - val_loss: 0.2452 - learning_rate: 3.9063e-06\nEpoch 63/100\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382ms/step - accuracy: 0.9030 - loss: 0.2911\nEpoch 63: val_accuracy did not improve from 0.92167\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 394ms/step - accuracy: 0.9030 - loss: 0.2911 - val_accuracy: 0.9210 - val_loss: 0.2431 - learning_rate: 3.9063e-06\nEpoch 64/100\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379ms/step - accuracy: 0.9035 - loss: 0.2984\nEpoch 64: val_accuracy did not improve from 0.92167\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m106s\u001b[0m 398ms/step - accuracy: 0.9035 - loss: 0.2983 - val_accuracy: 0.9210 - val_loss: 0.2417 - learning_rate: 3.9063e-06\nEpoch 65/100\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377ms/step - accuracy: 0.9042 - loss: 0.2951\nEpoch 65: val_accuracy did not improve from 0.92167\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 388ms/step - accuracy: 0.9043 - loss: 0.2951 - val_accuracy: 0.9207 - val_loss: 0.2426 - learning_rate: 3.9063e-06\nEpoch 66/100\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380ms/step - accuracy: 0.9067 - loss: 0.2856\nEpoch 66: val_accuracy improved from 0.92167 to 0.92233, saving model to best_model.h5\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m105s\u001b[0m 393ms/step - accuracy: 0.9067 - loss: 0.2856 - val_accuracy: 0.9223 - val_loss: 0.2427 - learning_rate: 3.9063e-06\nEpoch 67/100\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 377ms/step - accuracy: 0.9066 - loss: 0.2869\nEpoch 67: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n\nEpoch 67: val_accuracy did not improve from 0.92233\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 389ms/step - accuracy: 0.9066 - loss: 0.2869 - val_accuracy: 0.9223 - val_loss: 0.2429 - learning_rate: 3.9063e-06\nEpoch 68/100\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376ms/step - accuracy: 0.9011 - loss: 0.2949\nEpoch 68: val_accuracy did not improve from 0.92233\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m103s\u001b[0m 388ms/step - accuracy: 0.9011 - loss: 0.2949 - val_accuracy: 0.9220 - val_loss: 0.2429 - learning_rate: 1.9531e-06\nEpoch 69/100\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 376ms/step - accuracy: 0.9066 - loss: 0.2889\nEpoch 69: val_accuracy improved from 0.92233 to 0.92267, saving model to best_model.h5\n\u001b[1m266/266\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m104s\u001b[0m 390ms/step - accuracy: 0.9066 - loss: 0.2889 - val_accuracy: 0.9227 - val_loss: 0.2428 - learning_rate: 1.9531e-06\nEpoch 70/100\n\u001b[1m 53/266\u001b[0m \u001b[32m━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:21\u001b[0m 382ms/step - accuracy: 0.9136 - loss: 0.2717","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_35/3756421727.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mtrain_gen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_gen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    369\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    217\u001b[0m                 \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDistributedIterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m             ):\n\u001b[0;32m--> 219\u001b[0;31m                 \u001b[0mopt_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmulti_step_on_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mopt_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    876\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m       results = tracing_compilation.call_function(\n\u001b[0m\u001b[1;32m    879\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m       )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m   \u001b[0mbound_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbound_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m   return function._call_flat(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    140\u001b[0m       \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m   )\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1320\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1321\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1322\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_inference_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1323\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1324\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall_preflattened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m     \u001b[0;34m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mflat_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack_output\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py\u001b[0m in \u001b[0;36mcall_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mrecord\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_recording\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m           \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_bound_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m             outputs = self._bound_context.call_function(\n\u001b[0m\u001b[1;32m    252\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/context.py\u001b[0m in \u001b[0;36mcall_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1681\u001b[0m     \u001b[0mcancellation_context\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcancellation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1682\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcancellation_context\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1683\u001b[0;31m       outputs = execute.execute(\n\u001b[0m\u001b[1;32m   1684\u001b[0m           \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"utf-8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1685\u001b[0m           \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     54\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":27},{"cell_type":"markdown","source":"## 7. Генерация предсказаний и создание файла для сабмита.","metadata":{}},{"cell_type":"markdown","source":"Модель остановлена, т.к. заметных улучшений несколько эпох не показывали, а по требованиям уменьшение learning rate уменьшался бы еще несколько раз.\nУменьшаем углеродный след <3","metadata":{}},{"cell_type":"code","source":"# загрузка теста и нормализация\nX_test = images_sub.astype('float32') / 255.\npreds = model.predict(X_test, batch_size=64)\nlabels_sub = preds.argmax(axis=1).astype(int)\n\n# формирование файла\nsubmission = sample_sub.copy()\nsubmission['Category'] = labels_sub\nsubmission.to_csv('Fede_VV__try_3.csv', index=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-24T21:40:29.490707Z","iopub.execute_input":"2025-05-24T21:40:29.491056Z","iopub.status.idle":"2025-05-24T21:41:32.226874Z","shell.execute_reply.started":"2025-05-24T21:40:29.491006Z","shell.execute_reply":"2025-05-24T21:41:32.225858Z"}},"outputs":[{"name":"stdout","text":"\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 68ms/step\n","output_type":"stream"}],"execution_count":28}]}